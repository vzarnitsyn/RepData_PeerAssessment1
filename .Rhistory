x <- [1:121]
x <- 1:121
x[3:11]
cube <- function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
if (x > 5){}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
z <- 0
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
h <- function(x, y = NULL, d = 3L) {
z <- cbind(x, d)
if(!is.null(y))
z <- z + y
else
z <- z + f
g <- x + y / z
if(d == 3L)
return(g)
g <- g + 10
g
}
h(2)
f=2
h(2)
d
z
h(2,2)
h(2,2,3)
x1 <- 3L
x1
x1*5
library(xslx)
install.packages("xlsx")
library(xlsx)
source(xlsx)
install.packages("rJava")
source(xlsx)
install.packages("xlsx")
library(xlsx)
library(xlsx)
library(xlsx)
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf<-read.csv(path2csv,stringAsFactors=FALSE)
mydf<-read.csv(path2csv,stringsAsFactors=FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <-tbl_df(mydf)
rm("mydf")
cran
?manip
select(cran,ip_id,package,country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran,-time)
select(cran,-X:size)
select(cran,-X:-size)
select(cran,-(X:size))
select(cran,-size:-X))
select(cran,-size:-X)
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran,package=="swirl")
filter(cran,r_version=="3.1.1",country=="US")
?Comparison
filter(cran,r_version<="3.0.2",country=="IN")
filter(cran,country=="US"|country=="IN")
filter(cran,size>100500,r_os=="linux-gnu")
is,na(c(3,5,NA,10))
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,!is.na(r_version))
cran2<-select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3,size_mb=size/2^20)
mutate(cran3,size_mb=size/2^20,size_gb=size_mb/2^10)
mutate(cran3,correct_size=size+1000)
summarize(cran,avg_bytes=mean(size))
bye()
source("http://bioconductor.org/biocLite.R")
library(rhdf5)
biocLite("rhdf5")
biocLite("rhdf5")
library(rhdf5)
createh5createFile("example.h5")
created=h5createFile("example.h5")
created
created=h5createGroup("example.h5","foo")
created=h5createGroup("example.h5","baa")
created=h5createGroup("example.h5","foo/baa")
h5ls("example.h5")
A=matrix(1:10,nr=5,nc=2)
h5write(A,"example.h5","foo/A")
B=array(seq(0.1,2.0,by=0.1),dim=c(5,2,2))
attr(B,"scale")<-"liter"
h5write(B,"example.h5","foo/baa/B")
h5ls("example.h5")
df=data.frame(1L:5L,seq(0,1,length.out=5),c("ab","cde","fghi","a","s"),stringsAsFactors=FALSE)
h5write(df,"example.h5",df)
h5write(df,"example.h5","df")
h5ls("example.h5")
readA=h5read("example.h5","foo/A")
readB=h5read("example.h5","foo/baa/B")
readdf=h5read("example.h5","df")
readA
readB
readdf
h5write(c(12,13,14),"example.h5","foo/A",index=list(1:3,1))
h5read("example.h5","foo/A")
library(swirl)
swirl()
library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
cran
? group_by()
? group_by
by_package<-group_by(cran,package)
by_package
summarise(by_package,mean(size))
summarize(by_package,mean(size))
submit()
pack_sum
quantile(pack_sum$count,probs=0.99)
top_counts<-filter(by_package,count>679)
top_counts<-filter(by_package,by_package$count>679)
?filter
top_counts<-filter(pack_sum,count>679)
top_counts
head9top_counts,20
head(top_counts,20)
?desc
?arange
?arrange
arrange(top_counts,desc(count))
quantile(pack_sum$unique,probs=0.99)
top_unique<-filter(pack_sum,uniquet>465)
top_unique<-filter(pack_sum,unique>465)
top_unique
arrange(top_unique,desc(unique))
submit()
submit()
submit()
submit()
?select
submit()
submit()
cran%>%
select(ip_id)%>%
print()
submit()
cran%>%
select(ip_id,country,package,size)%>%
print()
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students,sex,count,-grade)
student2
students2
gather(students2,key,value,-grade)
gather(students2,sex_class,value,-grade)
gather(students2,sex_class,count,-grade)
res<-gather(students2,sex_class,count,-grade)
res
?separate
separate(res,sex_class,c("sex","class"))
submit()
submit
submit()
students3
submit()
?spread()
?spread
submit()
extract_numeric("class5")
?mutate
submit()
students4
submit()
submit()
submit()
passed
failed
passed<-mutate(status="passed")
passed<-mutate(passed,status="passed")
failed<-mutate(failed,status="failed")
rbind_list(passed,failed)
sat
?select
submit()
select(sat,-contaims("total"))
select(sat,-contains("total"))
sat2<-select(sat,-contains("total"))
sat3<-gather(sat2,part_sex,count,-score_range
)
sat3
separate(sat3,part_sex,c("part","sex"))
submit()
submit()
submit()
library(swirl)
swirl
swirl()
?dplyr
dplyr()
library(dplyr)
dplyr()
?dplyr
library(ggplot2)
?ggplot2
install.packages(c("dplyr", "rmarkdown"))
##This is a solution for the peer assignment 1.
###Loading and preprocessing the data
```{r, echo=TRUE}
#Here is an R chunck
setwd("C:/Coursera/Reproducible data analysis/Assignment1/Git")
datafile<-read.csv("activity.csv")
```
Now the data is downloaded in dataframe 'datafile'.
### What is mean total number of steps taken per day?
On the next step total number of steps taken per day will be calculated into new data frame 'stepsbyday'.
'dplyr' package will be used to group data and summarize.
```{r, echo=TRUE,results="asis"}
library(dplyr,warn.conflicts = FALSE)
#data is grouped by date and than summarize is being applieddataframe
stepsbydate<-summarize(group_by(datafile,date),Total_steps_per_day=sum(steps))
hist(stepsbydate$Total_steps_per_day,xlab='Total steps per day',main='Steps per day')
```
Now we can calculate mean and median of total number of steps taken per day.
First lets calculate the mean.
```{r, echo=TRUE}
mean_number_of_steps= mean(stepsbydate$Total_steps_per_day,na.rm=TRUE)
mean_number_of_steps
```
Next lets calculate the median:
```{r, echo=TRUE}
median_number_of_steps= median(stepsbydate$Total_steps_per_day,na.rm=TRUE)
median_number_of_steps
```
We can even report it inline. Mean number of steps per day is `r format(mean_number_of_steps,scientific=F)` and median number of steps is `r format(median_number_of_steps,scientific=F)`.
### What is the average daily activity pattern?
First we will make a time series plot of the 5 minutes intervals and the average number of steps taken (x), averaged across all days (y).
We will use the same approach with dplyr package we used to calculate total number of steps per day.
```{r}
stepsbyinterval<-summarize(group_by(datafile,interval),Average_steps=mean(steps,na.rm=TRUE))
plot(stepsbyinterval$interval,stepsbyinterval$Average_steps,xlab='Interval',ylab='Average number of steps', main='Steps pattern',type="l")
```
Let's figure out what interval has the maximum number of steps on average.
```{r}
max_interval <- stepsbyinterval$interval[which.max(stepsbyinterval$Average_steps)]
```
So the 5 minutes interval with maximum number of steps on average is `r max_interval`, which makes sense as it is most probaly 8.35 AM in the morning and good time for a run.
### Imputing missing values
Lets calculate the number of missing values in the dataset.
```{r}
missing_rows<-sum(is.na(datafile$steps))
```
So we do not have data on `r missing_rows` rows.
Lets replace missing values with average (i.e. mean) number of steps usually taken in this time interval.
This average number is usually floating point number and will be rounded to the nearest integer.
We will do it with the use of user-defined function 'corrected_steps' - it will have steps and interval as arguments, it will return steps if setps are valid or will compute and return average number of steps at that interval if steps are not defined (NA).
```{r}
corrected.steps<-function(steps,interval){
k<-length(steps)
steps2<-rep(0,k)
for (i in 1:k){
if (!is.na(steps[i])){
steps2[i]<-steps[i]
}
else {
steps2[i]<-stepsbyinterval$Average_steps[stepsbyinterval$interval==interval[i]]
}
}
return(round(steps2,digit=0))
}
```
We will create new database 'datafile2' .
```{r, echo=TRUE,results="asis"}
datafile2<-mutate(datafile,corr.steps=corrected.steps(steps,interval))
```
Now we will repeat histogram and calculation of mean and median for a new database.
```{r, echo=TRUE,results="asis"}
#data is grouped by date and than summarize is being applieddataframe
stepsbydate2<-summarize(group_by(datafile2,date),Total_steps_per_day=sum(corr.steps))
hist(stepsbydate2$Total_steps_per_day,xlab='Total steps per day',main='Steps per day(corrected)')
```
Now we can calculate mean and median of total number of steps taken per day in the corrected dataset.
First lets calculate the mean.
```{r, echo=TRUE}
mean_number_of_steps2= mean(stepsbydate2$Total_steps_per_day,na.rm=TRUE)
mean_number_of_steps2
```
Next lets calculate the median in the corrected dataset:
```{r, echo=TRUE}
median_number_of_steps2= median(stepsbydate2$Total_steps_per_day,na.rm=TRUE)
median_number_of_steps2
```
Now we can compare uncorrected and corrected results inline. Mean number of uncorrected steps per day is `r format(mean_number_of_steps,scientific=F)` and after correction it is `r format(mean_number_of_steps2,scientific=F)`.
Median number of steps was `r format(median_number_of_steps,scientific=F)` and after correction is `r format(median_number_of_steps2,scientific=F)`.
As one can see the proposed correction did not change the mean and median much. What is interesting the corrected values are somewhat lower than initial data. This seems counterintuitive. Lets try to find number of missing dates in original and corrected datsets.
``` {r}
Number_of_missing_dates <-sum(is.na(stepsbydate$Total_steps_per_day))
Number_of_missing_dates
```
``` {r}
Number_of_missing_dates2 <-sum(is.na(stepsbydate2$Total_steps_per_day))
Number_of_missing_dates2
```
The explanation is in the fact that new dataset has values for 8 more days which were missing in the original dataset. And even thoug total number of steps in database is increased number of days with data increased as well.
### Are there changes in activity patterns between weekdays and weekends
Lets add day of the week information to the corrected dataset
```{r}
aWeekDay<-weekdays(strptime(datafile2$date,format("%Y-%m-%d ")))
L<-dim(datafile2)[1]
weekD<-rep("",L)
for (i in 1:L) {
if (aWeekDay[i] %in% c("Saturday","Sunday")) {
weekD[i]<-"weekend"
}
else {
weekD[i]<-"weekday"
}
}
datafile2<-cbind(datafile2,weekD)
```
Now it is time to plot a comparison. I am going to use ggplot2 package
```{r}
library(ggplot2)
#Now we group not only by interval but also by weekend/weekday
stepsbyinterval2<-summarize(group_by(datafile2,interval,weekD),Average_steps=mean(corr.steps))
g<-ggplot(stepsbyinterval2,aes(interval,Average_steps))+geom_line(size=1)
g<-g+facet_grid(weekD~.,scales="free")
g<-g+labs(x="Interval",y="Average number of steps")
g<-g+labs(title=expression("Steps profiling weekends or weekdays"))
g
```
### Some final notes.
I had a bit of a hard time to make R markdown to work. My solution was googled. In essence I needed to upgrade several software packages to the most recent version.
Here is the list of version used for this project:
R-studio - 0.98.1091
R - 3.1.2
dplyr - 0.4.1
ggplot2 - 1.0.0
rmarkdown - 0.4.2
L
library(knitr)
knit2html('PA1_template.Rmd')
knit2html('PA1_template.Rmd')
